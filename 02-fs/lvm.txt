PS C:\Git\otus-linux\02-fs> vagrant ssh

[vagrant@lvm ~]$ lsblk
NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda                       8:0    0   40G  0 disk
├─sda1                    8:1    0    1M  0 part
├─sda2                    8:2    0    1G  0 part /boot
└─sda3                    8:3    0   39G  0 part
  ├─VolGroup00-LogVol00 253:0    0 37.5G  0 lvm  /
  └─VolGroup00-LogVol01 253:1    0  1.5G  0 lvm  [SWAP]
sdb                       8:16   0   10G  0 disk
sdc                       8:32   0    2G  0 disk
sdd                       8:48   0    1G  0 disk
sde                       8:64   0    1G  0 disk
[vagrant@lvm ~]$ sudo su
[root@lvm vagrant]# lvmdiskscan
  /dev/VolGroup00/LogVol00 [     <37.47 GiB]
  /dev/VolGroup00/LogVol01 [       1.50 GiB]
  /dev/sda2                [       1.00 GiB]
  /dev/sda3                [     <39.00 GiB] LVM physical volume
  /dev/sdb                 [      10.00 GiB]
  /dev/sdc                 [       2.00 GiB]
  /dev/sdd                 [       1.00 GiB]
  /dev/sde                 [       1.00 GiB]
  4 disks
  3 partitions
  0 LVM physical volume whole disks
  1 LVM physical volume
[root@lvm vagrant]# pvcreate /dev/sdb
  Physical volume "/dev/sdb" successfully created.
[root@lvm vagrant]# vgcreate otus /dev/sdb
  Volume group "otus" successfully created
[root@lvm vagrant]# lvcreate -l+80%FREE -n test otus
  Logical volume "test" created.
[root@lvm vagrant]# vgdisplay otus
  --- Volume group ---
  VG Name               otus
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  2
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                1
  Open LV               0
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               <10.00 GiB
  PE Size               4.00 MiB
  Total PE              2559
  Alloc PE / Size       2047 / <8.00 GiB
  Free  PE / Size       512 / 2.00 GiB
  VG UUID               rz3Xtv-vG9t-4OeQ-1OET-70Aw-brTB-Kc75nT
[root@lvm vagrant]# vgdisplay -v otus | grep 'PV Name'
  PV Name               /dev/sdb
[root@lvm vagrant]# lvdisplay /dev/otus/test
  --- Logical volume ---
  LV Path                /dev/otus/test
  LV Name                test
  VG Name                otus
  LV UUID                BL9OcR-PVdz-cBKy-yNf0-Ox85-FnLT-eHbWsY
  LV Write Access        read/write
  LV Creation host, time lvm, 2019-02-10 18:01:49 +0000
  LV Status              available
  # open                 0
  LV Size                <8.00 GiB
  Current LE             2047
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:2
[root@lvm vagrant]# vgs
  VG         #PV #LV #SN Attr   VSize   VFree
  VolGroup00   1   2   0 wz--n- <38.97g    0
  otus         1   1   0 wz--n- <10.00g 2.00g
[root@lvm vagrant]# lvs
  LV       VG         Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  LogVol00 VolGroup00 -wi-ao---- <37.47g
  LogVol01 VolGroup00 -wi-ao----   1.50g
  test     otus       -wi-a-----  <8.00g
[root@lvm vagrant]# lvcreate -L100M -n small otus
  Logical volume "small" created.
[root@lvm vagrant]#  lvs
  LV       VG         Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  LogVol00 VolGroup00 -wi-ao---- <37.47g
  LogVol01 VolGroup00 -wi-ao----   1.50g
  small    otus       -wi-a----- 100.00m
  test     otus       -wi-a-----  <8.00g
[root@lvm vagrant]# mkfs.ext4 /dev/otus/test
 mke2fs 1.42.9 (28-Dec-2013)
 Filesystem label=
 OS type: Linux
 Block size=4096 (log=2)
 Fragment size=4096 (log=2)
 Stride=0 blocks, Stripe width=0 blocks
 524288 inodes, 2096128 blocks
 104806 blocks (5.00%) reserved for the super user
 First data block=0
 Maximum filesystem blocks=2147483648
 64 block groups
 32768 blocks per group, 32768 fragments per group
 8192 inodes per group
 Superblock backups stored on blocks:
        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632

 Allocating group tables: done
 Writing inode tables: done
 Creating journal (32768 blocks): done
 Writing superblocks and filesystem accounting information: done
[root@lvm vagrant]# mkdir /data
[root@lvm vagrant]# mount /dev/otus/test /data/
[root@lvm vagrant]# mount | grep /data
 /dev/mapper/otus-test on /data type ext4 (rw,relatime,seclabel,data=ordered)
[root@lvm vagrant]# pvcreate /dev/sdc
  Physical volume "/dev/sdc" successfully created.
[root@lvm vagrant]# vgextend otus /dev/sdc
  Volume group "otus" successfully extended
[root@lvm vagrant]# vgdisplay -v otus | grep 'PV Name'
  PV Name               /dev/sdb
  PV Name               /dev/sdc
[root@lvm vagrant]# vgs
  VG         #PV #LV #SN Attr   VSize   VFree
  VolGroup00   1   2   0 wz--n- <38.97g     0
  otus         2   2   0 wz--n-  11.99g <3.90g
[root@lvm vagrant]# dd if=/dev/zero of=/data/test.log bs=1M count=8000 status=progress
 8199864320 bytes (8.2 GB) copied, 32.138124 s, 255 MB/s
 dd: error writing ‘/data/test.log’: No space left on device
 7880+0 records in
 7879+0 records out
 8262189056 bytes (8.3 GB) copied, 32.3716 s, 255 MB/s
[root@lvm vagrant]# df -Th /data/
 Filesystem            Type  Size  Used Avail Use% Mounted on
 /dev/mapper/otus-test ext4  7.8G  7.8G     0 100% /data
[root@lvm vagrant]# lvextend -l+80%FREE /dev/otus/test
  Size of logical volume otus/test changed from <8.00 GiB (2047 extents) to <11.12 GiB (2846 extents).
  Logical volume otus/test successfully resized.
[root@lvm vagrant]# lvs /dev/otus/test
  LV   VG   Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  test otus -wi-ao---- <11.12g
[root@lvm vagrant]#  df -Th /data
 Filesystem            Type  Size  Used Avail Use% Mounted on
 /dev/mapper/otus-test ext4  7.8G  7.8G     0 100% /data
[root@lvm vagrant]# resize2fs /dev/otus/test
 resize2fs 1.42.9 (28-Dec-2013)
 Filesystem at /dev/otus/test is mounted on /data; on-line resizing required
 old_desc_blocks = 1, new_desc_blocks = 2
 The filesystem on /dev/otus/test is now 2914304 blocks long.
[root@lvm vagrant]# df -Th /data
 Filesystem            Type  Size  Used Avail Use% Mounted on
 /dev/mapper/otus-test ext4   11G  7.8G  2.6G  76% /data
[root@lvm vagrant]# lvreduce /dev/otus/test -L 10G
  WARNING: Reducing active and open logical volume to 10.00 GiB.
  THIS MAY DESTROY YOUR DATA (filesystem etc.)
 Do you really want to reduce otus/test? [y/n]: y
  Size of logical volume otus/test changed from <11.12 GiB (2846 extents) to 10.00 GiB (2560 extents).
  Logical volume otus/test successfully resized.
[root@lvm vagrant]# df -Th /data/
 Filesystem            Type  Size  Used Avail Use% Mounted on
 /dev/mapper/otus-test ext4   11G  7.8G  2.6G  76% /data
[root@lvm vagrant]#  lvcreate -L 500M -s -n test-snap /dev/otus/test
  Logical volume "test-snap" created.
[root@lvm vagrant]# vgs -o +lv_size,lv_name | grep test
  otus         2   3   1 wz--n-  11.99g <1.41g  10.00g test
  otus         2   3   1 wz--n-  11.99g <1.41g 500.00m test-snap
[root@lvm vagrant]# lsblk
 NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
 sda                       8:0    0   40G  0 disk
 ├─sda1                    8:1    0    1M  0 part
 ├─sda2                    8:2    0    1G  0 part /boot
 └─sda3                    8:3    0   39G  0 part
   ├─VolGroup00-LogVol00 253:0    0 37.5G  0 lvm  /
   └─VolGroup00-LogVol01 253:1    0  1.5G  0 lvm  [SWAP]
 sdb                       8:16   0   10G  0 disk
 ├─otus-small            253:3    0  100M  0 lvm
 └─otus-test-real        253:4    0   10G  0 lvm
   ├─otus-test           253:2    0   10G  0 lvm  /data
   └─otus-test--snap     253:6    0   10G  0 lvm
 sdc                       8:32   0    2G  0 disk
 ├─otus-test-real        253:4    0   10G  0 lvm
 │ ├─otus-test           253:2    0   10G  0 lvm  /data
 │ └─otus-test--snap     253:6    0   10G  0 lvm
 └─otus-test--snap-cow   253:5    0  500M  0 lvm
   └─otus-test--snap     253:6    0   10G  0 lvm
 sdd                       8:48   0    1G  0 disk
 sde                       8:64   0    1G  0 disk
[root@lvm vagrant]# mkdir /data-snap
[root@lvm vagrant]# mount /dev/otus/test-snap /data-snap/
 mount: wrong fs type, bad option, bad superblock on /dev/mapper/otus-test--snap,
       missing codepage or helper program, or other error

       In some cases useful info is found in syslog - try
       dmesg | tail or so.
[root@lvm vagrant]# pvcreate /dev/sd{d,e}
  Physical volume "/dev/sdd" successfully created.
  Physical volume "/dev/sde" successfully created.
[root@lvm vagrant]# vgcreate vg0 /dev/sd{d,e}
  Volume group "vg0" successfully created
[root@lvm vagrant]# lvcreate -l+80%FREE -m1 -n mirror vg0
  Logical volume "mirror" created.
[root@lvm vagrant]# lvs
  LV       VG         Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  LogVol00 VolGroup00 -wi-ao---- <37.47g
  LogVol01 VolGroup00 -wi-ao----   1.50g
  small    otus       -wi-a----- 100.00m
  test     otus       Owi-a-s---  10.00g
  mirror   vg0        rwi-a-r--- 816.00m                                    70.50